accum-grad: 2
adim: 256
aheads: 4
backend: pytorch
batch-size: 32
cross-operator: sum
cross-self: true
cross-src: true
cross-to-asr: true
cross-weight: 1
cross-weight-learnable: true
dlayers: 6
dropout-rate: 0.1
dunits: 1024
elayers: 6
epochs: 30
eunits: 1024
grad-clip: 5
lsm-weight: 0.1
maxlen-in: 512
maxlen-out: 150
model-module: espnet.nets.pytorch_backend.e2e_asr_muldec_transf:E2E
mtlalpha: 0.2
opt: noam
outsre:
- S102
- S179
- S201
- S202
- S203
- S300
patience: 0
sortagrad: 0
srelambda: 0.7
transformer-attn-dropout-rate: 0.0
transformer-init: pytorch
transformer-input-layer: conv2d
transformer-length-normalized-loss: false
transformer-lr: 5.0
transformer-warmup-steps: 25000
